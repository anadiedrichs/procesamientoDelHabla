{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anadiedrichs/procesamientoDelHabla/blob/main/clase_1_vectorizacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5hxxkdAQJg"
      },
      "source": [
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Vectorización\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCED1hh-Ioyf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XA8VS2dVU3tO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOa4JPSCJ29"
      },
      "source": [
        "## Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIO7b8GjAC17"
      },
      "outputs": [],
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqdaTmO8P1r"
      },
      "source": [
        "Documento 1 --> que dia es hoy \\\n",
        "Documento 2 --> martes el dia de hoy es martes \\\n",
        "Documento 3 --> martes muchas gracias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ccchOeZuShL",
        "outputId": "2d5b5eac-60f4-421b-bf02-1326ec6031ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['que dia es hoy', 'martes el dia de hoy es martes',\n",
              "       'martes muchas gracias'], dtype='<U30')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHxBRNzCMOS"
      },
      "source": [
        "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
        "- Cada documento transformarlo en una lista de términos\n",
        "- Armar un vector de términos no repetidos de todos los documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZqTOZzDI7uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3d2f08-1d22-43b1-b397-12e6de702f1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['que', 'dia', 'es', 'hoy']),\n",
              "       list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']),\n",
              "       list(['martes', 'muchas', 'gracias'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "documentos = np.char.split(corpus)\n",
        "documentos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.isin(documentos[0][0],documentos[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0GD_Xle81hR",
        "outputId": "b6dd6532-ad1c-4174-f188-08516d27f85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "\n",
        "for doc in documentos:\n",
        "  for word in doc:\n",
        "    if np.isin(word,tokens) == False:\n",
        "      tokens = np.append(tokens,word)\n",
        "      #print(word)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAKCtS1Z8YL-",
        "outputId": "9fa9d513-2663-4415-aa28-f36576586083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['que' 'dia' 'es' 'hoy' 'martes' 'el' 'de' 'muchas' 'gracias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhH983FI7It"
      },
      "source": [
        "### 2- OneHot encoding\n",
        "Dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os0AAQo6I6Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8073e33c-75aa-4fa0-a4f3-de70d5a2943f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "n_tokens = len(tokens)\n",
        "n_doc = documentos.size\n",
        "\n",
        "matriz = np.zeros((n_doc,n_tokens),dtype = np.uint8)\n",
        "matriz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fila = 0\n",
        "for doc in documentos:\n",
        "  #print(doc)\n",
        "  for word in doc:\n",
        "    #print(word)\n",
        "    if word in tokens:\n",
        "      i = tokens.tolist().index(word)\n",
        "      #print(i)\n",
        "      matriz[fila,i] = 1\n",
        "\n",
        "  fila = fila + 1\n",
        "\n",
        "print(matriz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCBTuA8XFIMr",
        "outputId": "1fa344f0-8b7f-4944-e6ae-5e4449586d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(documento_list, tokens_list):\n",
        "\n",
        "  n_tokens = len(tokens_list)\n",
        "  n_doc = documento_list.size\n",
        "  matriz = np.zeros((n_doc,n_tokens),dtype = np.uint8)\n",
        "  fila = 0\n",
        "\n",
        "  for doc in documento_list:\n",
        "    #print(doc)\n",
        "    for word in doc:\n",
        "      #print(word)\n",
        "      if word in tokens_list:\n",
        "        i = tokens.tolist().index(word)\n",
        "        #print(i)\n",
        "        matriz[fila,i] = 1\n",
        "\n",
        "    fila = fila + 1\n",
        "\n",
        "  return matriz\n",
        "\n",
        "print(one_hot_encoding(documentos, tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKc6sve-L65_",
        "outputId": "d46a8d24-dbe4-4bc6-bdf9-4ef217292669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyWGmCpJVQL"
      },
      "source": [
        "### 3- Vectores de frecuencia\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqij_7eHJbUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331257d8-e485-486d-9d00-25915e95b12a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "n_tokens = len(tokens)\n",
        "n_doc = documentos.size\n",
        "\n",
        "frecuencias = np.zeros((n_doc,n_tokens),dtype = np.uint8)\n",
        "frecuencias\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fila = 0\n",
        "for doc in documentos:\n",
        "  #print(doc)\n",
        "  for word in doc:\n",
        "    #print(word)\n",
        "    if word in tokens:\n",
        "      i = tokens.tolist().index(word)\n",
        "      #print(i)\n",
        "      frecuencias[fila,i]= frecuencias[fila,i]+1\n",
        "\n",
        "  fila = fila + 1\n",
        "\n",
        "print(frecuencias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fc0071-b99a-4816-ecb2-d4f335b74c89",
        "id": "7QoJun74Kdlw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frecuency_matrix(documento_list, tokens_list):\n",
        "  n_tokens = len(tokens_list)\n",
        "  n_doc = documento_list.size\n",
        "  frecuencias = np.zeros((n_doc,n_tokens),dtype = np.uint8)\n",
        "\n",
        "  fila = 0\n",
        "  for doc in documento_list:\n",
        "    #print(doc)\n",
        "    for word in doc:\n",
        "      #print(word)\n",
        "      if word in tokens_list:\n",
        "        i = tokens_list.tolist().index(word)\n",
        "        #print(i)\n",
        "        frecuencias[fila,i]= frecuencias[fila,i]+1\n",
        "\n",
        "    fila = fila + 1\n",
        "\n",
        "  return frecuencias\n",
        "\n",
        "print(frecuency_matrix(documentos, tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd457y3nMop5",
        "outputId": "63319c23-6617-4235-a377-eade5a2d5d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ot8HvWJcBu"
      },
      "source": [
        "### 4- TF-IDF\n",
        "Dada una lista de textos, devolver una matriz con la representacion TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waG_oWtpJjRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2102cbf-32ac-48bd-c297-98e0026285de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.47712125 0.17609126 0.17609126 0.17609126 0.         0.47712125\n",
            " 0.47712125 0.47712125 0.47712125]\n",
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47712125, 0.17609126, 0.17609126, 0.17609126, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.17609126, 0.17609126, 0.17609126, 0.        ,\n",
              "        0.47712125, 0.47712125, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47712125, 0.47712125]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# calcular IDF\n",
        "# Se obtiene como la división de la cantidad de documentos sobre la\n",
        "# suma en axis=0 (vertical) del OneHotEncoding.\n",
        "def inverse_document_frequency(documento_list, tokens_list):\n",
        "\n",
        "  n_doc = documento_list.size\n",
        "\n",
        "  Freq = frecuency_matrix(documento_list, tokens_list)\n",
        "\n",
        "  div = (n_doc * 1.0) / (np.sum(Freq,axis=0) * 1.0)\n",
        "\n",
        "  #print(div)\n",
        "\n",
        "  return np.log10(div)\n",
        "\n",
        "IDF = inverse_document_frequency(documentos, tokens)\n",
        "\n",
        "print(IDF )\n",
        "# calcular TF\n",
        "TF = frecuency_matrix(documentos, tokens)\n",
        "print(TF)\n",
        "# regresar TF-IDF\n",
        "\n",
        "def TF_IDF_function(documento_list, tokens_list):\n",
        "  return frecuency_matrix(documentos, tokens) * inverse_document_frequency(documentos, tokens)\n",
        "\n",
        "\n",
        "TF_IDF_function(documentos, tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usar sklearn para procesar texto"
      ],
      "metadata": {
        "id": "NbEO4NucI_4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear un vector de frecuencia de documentos de un corpus"
      ],
      "metadata": {
        "id": "_rOuIzmLMOq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ],
      "metadata": {
        "id": "YUNP-x2UL3hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "vector = vectorizer.transform(corpus)\n"
      ],
      "metadata": {
        "id": "gKQx1Pj7JADt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtengo vector de frecuencias"
      ],
      "metadata": {
        "id": "dHkqXsJQL7bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9s2kJFuL-wA",
        "outputId": "24a7d778-29f7-4e04-cece-341ed0239655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1 0 1 0 0 1]\n",
            " [1 1 1 1 0 1 2 0 0]\n",
            " [0 0 0 0 1 0 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtengo vocabulario"
      ],
      "metadata": {
        "id": "sKlONi7eMCb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP8ufohUMD1U",
        "outputId": "d035dec5-5166-488e-b922-3900985467ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding\n",
        "\n"
      ],
      "metadata": {
        "id": "SbD_tE8dMcZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usar sklearn para obtener la representacion one-hot encoding de un corpus de documentos"
      ],
      "metadata": {
        "id": "rHsfwZHdM0Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Crear un vectorizador para contar la frecuencia de las palabras\n",
        "vectorizer = CountVectorizer(binary=True)  # binary=True para one-hot encoding\n",
        "vectorizer.fit(corpus)\n",
        "\n",
        "# Obtener la representación one-hot encoding\n",
        "one_hot_vector = vectorizer.transform(corpus)"
      ],
      "metadata": {
        "id": "5irIx9Z-MzsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar la matriz resultante\n",
        "print(one_hot_vector.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Jh3alUMwR7",
        "outputId": "1a65ab05-11e4-4522-940d-98c624344311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1 0 1 0 0 1]\n",
            " [1 1 1 1 0 1 1 0 0]\n",
            " [0 0 0 0 1 0 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar el vocabulario\n",
        "print(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvNFwwmQMu1_",
        "outputId": "1c5d94cc-aa57-46bd-9c65-12b87c9bf6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF\n",
        "\n"
      ],
      "metadata": {
        "id": "uzJIEfmMM9nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ARujodGDNAu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Crear un vectorizador TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Ajustar el vectorizador al corpus\n",
        "tfidf_vectorizer.fit(corpus)\n",
        "\n",
        "# Obtener la representación TF-IDF\n",
        "tfidf_matrix = tfidf_vectorizer.transform(corpus)\n"
      ],
      "metadata": {
        "id": "MYcFAnKvNOjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar la matriz TF-IDF\n",
        "print(tfidf_matrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQLAieq_NI60",
        "outputId": "001e00cf-d60e-465f-e8e7-1785f013c178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.45985353 0.         0.45985353 0.         0.45985353\n",
            "  0.         0.         0.60465213]\n",
            " [0.40659827 0.30922846 0.40659827 0.30922846 0.         0.30922846\n",
            "  0.61845693 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.62276601 0.\n",
            "  0.4736296  0.62276601 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar el vocabulario\n",
        "print(tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ6oRxqVNJIq",
        "outputId": "37484dff-9459-411a-e258-9a8125461b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio\n",
        "\n",
        "**Dado el siguiente texto**\n",
        "\n",
        "Aplastamiento de las Gotas - Julio Cortázar\n",
        "\n",
        "Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\n",
        "\n",
        "Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós."
      ],
      "metadata": {
        "id": "fps1NU66U4cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"Aplastamiento de las Gotas - Julio Cortázar\",\n",
        "          \"Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\",\n",
        "          \"Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós.\"]\n"
      ],
      "metadata": {
        "id": "grRaq08KVNao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "corpus_dict = [\n",
        "    {\"id\": 0, \"texto\": \"Aplastamiento de las Gotas - Julio Cortázar\"},\n",
        "    {\"id\": 1, \"texto\": \"Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\"},\n",
        "    {\"id\": 2, \"texto\": \"Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós.\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "i_Z_PpQGZY9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3xgOmaqINWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usar la libreria Numpy y sklearn para calcular vector de frecuencia, one-hot-encoding, y TF-IDF**"
      ],
      "metadata": {
        "id": "iE_ocIdPIOMi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IkZjOicpIVS9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}